{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3173b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"8c57fbc8\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import gradio as gr\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"import json\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"from dotenv import load_dotenv\\n\",\n",
    "    \"from langchain_groq import ChatGroq\\n\",\n",
    "    \"from sentence_transformers import SentenceTransformer\\n\",\n",
    "    \"import faiss\\n\",\n",
    "    \"load_dotenv()\\n\",\n",
    "    \"GROQ_API_KEY = os.getenv(\\\"GROQ_API_KEY\\\")\\n\",\n",
    "    \"llm = ChatGroq(model=\\\"llama-3.1-8b-instant\\\")\\n\",\n",
    "    \"embedding_model = SentenceTransformer(\\\"all-MiniLM-L6-v2\\\")\\n\",\n",
    "    \"d = 384\\n\",\n",
    "    \"if os.path.exists(\\\"user_history.index\\\"):\\n\",\n",
    "    \"    index = faiss.read_index(\\\"user_history.index\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    index = faiss.IndexFlatL2(d)\\n\",\n",
    "    \"def load_user_history():\\n\",\n",
    "    \"    if os.path.exists(\\\"user_history.json\\\"):\\n\",\n",
    "    \"        with open(\\\"user_history.json\\\", \\\"r\\\") as file:\\n\",\n",
    "    \"            return json.load(file)\\n\",\n",
    "    \"    return []\\n\",\n",
    "    \"def store_user_history(data, score, feedback):\\n\",\n",
    "    \"    history = load_user_history()\\n\",\n",
    "    \"    entry = {\\\"vitals\\\": data, \\\"score\\\": score, \\\"feedback\\\": feedback}\\n\",\n",
    "    \"    history.append(entry)\\n\",\n",
    "    \"    with open(\\\"user_history.json\\\", \\\"w\\\") as file:\\n\",\n",
    "    \"        json.dump(history, file, indent=4)\\n\",\n",
    "    \"    if feedback:\\n\",\n",
    "    \"        with open(\\\"feedback.txt\\\", \\\"a\\\") as file:\\n\",\n",
    "    \"            file.write(f\\\"{feedback}\\\\n\\\")\\n\",\n",
    "    \"    embedding = embedding_model.encode(json.dumps(entry)).tolist()\\n\",\n",
    "    \"    index.add(np.array([embedding], dtype=np.float32))\\n\",\n",
    "    \"    faiss.write_index(index, \\\"user_history.index\\\")\\n\",\n",
    "    \"def retrieve_similar_cases(data):\\n\",\n",
    "    \"    if index.ntotal == 0:\\n\",\n",
    "    \"        return []\\n\",\n",
    "    \"    embedding = embedding_model.encode(json.dumps(data)).tolist()\\n\",\n",
    "    \"    distances, indices = index.search(np.array([embedding], dtype=np.float32), k=3)\\n\",\n",
    "    \"    history = load_user_history()\\n\",\n",
    "    \"    return [history[i] for i in indices[0] if i < len(history)]\\n\",\n",
    "    \"def predict_recovery_score(data):\\n\",\n",
    "    \"    prompt = f\\\"\\\"\\\"\\n\",\n",
    "    \"    Given vitals:\\n\",\n",
    "    \"    - Heart Rate: {data['heart_rate']}\\n\",\n",
    "    \"    - BP: {data['bp']}\\n\",\n",
    "    \"    - Oxygen Saturation: {data['oxygen_saturation']}\\n\",\n",
    "    \"    - Symptoms: {data['symptoms']}\\n\",\n",
    "    \"    Predict a recovery score between 0-100. Only give a score, no description.\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    return llm.predict(prompt).strip()\\n\",\n",
    "    \"def generate_recovery_plan(score, feedback_history, user_history, similar_cases):\\n\",\n",
    "    \"    prompt = f\\\"\\\"\\\"\\n\",\n",
    "    \"    The patient's recovery score is {score}. Suggest a structured recovery plan.\\n\",\n",
    "    \"    Consider the following:\\n\",\n",
    "    \"    - Feedback History: {feedback_history}\\n\",\n",
    "    \"    - User History: {user_history}\\n\",\n",
    "    \"    - Similar Cases: {similar_cases}\\n\",\n",
    "    \"    Adjust the plan to address any concerns or requests raised in the feedback.\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    return llm.predict(prompt).strip()\\n\",\n",
    "    \"def get_feedback_history():\\n\",\n",
    "    \"    if os.path.exists(\\\"feedback.txt\\\"):\\n\",\n",
    "    \"        with open(\\\"feedback.txt\\\", \\\"r\\\") as file:\\n\",\n",
    "    \"            return file.read()\\n\",\n",
    "    \"    return \\\"No feedback yet.\\\"\\n\",\n",
    "    \"def process_input(heart_rate, bp, oxygen_saturation, symptoms):\\n\",\n",
    "    \"    data = {\\n\",\n",
    "    \"        \\\"heart_rate\\\": heart_rate,\\n\",\n",
    "    \"        \\\"bp\\\": bp,\\n\",\n",
    "    \"        \\\"oxygen_saturation\\\": oxygen_saturation,\\n\",\n",
    "    \"        \\\"symptoms\\\": symptoms,\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"    score = predict_recovery_score(data)\\n\",\n",
    "    \"    feedback_history = get_feedback_history()\\n\",\n",
    "    \"    user_history = load_user_history()\\n\",\n",
    "    \"    similar_cases = retrieve_similar_cases(data)\\n\",\n",
    "    \"    plan = generate_recovery_plan(score, feedback_history, user_history, similar_cases)\\n\",\n",
    "    \"    return score, plan, \\\"Please provide feedback on the generated recovery plan.\\\"\\n\",\n",
    "    \"def process_feedback(heart_rate, bp, oxygen_saturation, symptoms, feedback):\\n\",\n",
    "    \"    data = {\\n\",\n",
    "    \"        \\\"heart_rate\\\": heart_rate,\\n\",\n",
    "    \"        \\\"bp\\\": bp,\\n\",\n",
    "    \"        \\\"oxygen_saturation\\\": oxygen_saturation,\\n\",\n",
    "    \"        \\\"symptoms\\\": symptoms,\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"    score = predict_recovery_score(data)\\n\",\n",
    "    \"    store_user_history(data, score, feedback)\\n\",\n",
    "    \"    feedback_history = get_feedback_history()\\n\",\n",
    "    \"    return f\\\"Thank you for your feedback: {feedback}. It has been stored successfully. Current Feedback History: {feedback_history}\\\"\\n\",\n",
    "    \"demo = gr.Blocks()\\n\",\n",
    "    \"with demo:\\n\",\n",
    "    \"    gr.Markdown(\\\"# AI Recovery Score & Plan Generator with Feedback\\\")\\n\",\n",
    "    \"    with gr.Row():\\n\",\n",
    "    \"        with gr.Column():\\n\",\n",
    "    \"            heart_rate = gr.Number(label=\\\"Heart Rate\\\")\\n\",\n",
    "    \"            bp = gr.Textbox(label=\\\"Blood Pressure\\\")\\n\",\n",
    "    \"            oxygen_saturation = gr.Textbox(label=\\\"Oxygen Saturation\\\")\\n\",\n",
    "    \"            symptoms = gr.Textbox(label=\\\"Symptoms\\\")\\n\",\n",
    "    \"            feedback = gr.Textbox(label=\\\"Feedback\\\", visible=False)\\n\",\n",
    "    \"            submit = gr.Button(\\\"Submit Vitals\\\")\\n\",\n",
    "    \"            feedback_button = gr.Button(\\\"Submit Feedback\\\", visible=False)\\n\",\n",
    "    \"        with gr.Column():\\n\",\n",
    "    \"            recovery_score = gr.Textbox(label=\\\"Predicted Recovery Score\\\", interactive=False)\\n\",\n",
    "    \"            recovery_plan = gr.Textbox(label=\\\"Recovery Plan\\\", interactive=False)\\n\",\n",
    "    \"            feedback_prompt = gr.Textbox(label=\\\"Feedback Prompt\\\", interactive=False)\\n\",\n",
    "    \"    submit.click(\\n\",\n",
    "    \"        process_input,\\n\",\n",
    "    \"        inputs=[heart_rate, bp, oxygen_saturation, symptoms],\\n\",\n",
    "    \"        outputs=[recovery_score, recovery_plan, feedback_prompt],\\n\",\n",
    "    \"    ).then(\\n\",\n",
    "    \"        lambda: (gr.update(visible=True), gr.update(visible=True)),\\n\",\n",
    "    \"        outputs=[feedback, feedback_button],\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"    feedback_button.click(\\n\",\n",
    "    \"        process_feedback,\\n\",\n",
    "    \"        inputs=[heart_rate, bp, oxygen_saturation, symptoms, feedback],\\n\",\n",
    "    \"        outputs=[feedback_prompt],\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"if __name__ == \\\"__main__\\\":\\n\",\n",
    "    \"    demo.launch(share=True)\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"language_info\": {\n",
    "   \"name\": \"python\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 5\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
